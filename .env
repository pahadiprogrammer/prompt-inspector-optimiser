# Environment variables for Prompt Inspector and Optimizer

# Server settings
PORT=8000
HOST=0.0.0.0
DEBUG=True

# LLM API settings
# Uncomment and add your API key for the service you want to use
# OPENAI_API_KEY=your_openai_api_key_here
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# OPENROUTER_API_KEY=your_openrouter_api_key_here

# Default LLM API to use (openai, anthropic, openrouter)
DEFAULT_LLM_API=openai

# Rate limiting
MAX_REQUESTS_PER_MINUTE=10
MAX_QUEUE_SIZE=100
